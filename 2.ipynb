{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from os import listdir\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to load images and masks from directory\n",
    "def load_dir(dir):\n",
    "    images = []\n",
    "    masks = []\n",
    "    labels = []\n",
    "    resize = T.Resize((128, 128))\n",
    "    for subfolder in ['infected', 'notinfected']:\n",
    "        subdir_path = os.path.join(dir, subfolder)\n",
    "        for file in listdir(subdir_path):\n",
    "            if file.endswith(\".png\"):\n",
    "                image_path = os.path.join(subdir_path, file)\n",
    "                image = read_image(image_path, ImageReadMode.GRAY)\n",
    "                image = resize(image)\n",
    "                image = TF.convert_image_dtype(image, dtype=torch.float32)\n",
    "\n",
    "                mask_file = file.replace('.png', '_mask.png')\n",
    "                mask_path = os.path.join(subdir_path, mask_file)\n",
    "                mask = read_image(mask_path, ImageReadMode.GRAY)\n",
    "                mask = resize(mask)\n",
    "                mask = TF.convert_image_dtype(mask, dtype=torch.float32)\n",
    "\n",
    "                images.append(image)\n",
    "                masks.append(mask)\n",
    "                labels.append(subfolder)\n",
    "\n",
    "    return images, masks, labels\n",
    "\n",
    "# Custom Dataset class\n",
    "class PCauseDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.images, self.masks, labels = load_dir(path)\n",
    "        self.transform = transform\n",
    "\n",
    "        encLabel = LabelEncoder().fit_transform(labels)\n",
    "        self.labels = torch.from_numpy(encLabel)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        mask = self.masks[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "# Path to the train and test directories\n",
    "train_path = \"grayscale_dataset/train\"\n",
    "test_path = \"grayscale_dataset/test\"\n",
    "\n",
    "# Transformation for data augmentation\n",
    "transform_augmentation = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.RandomRotation(90),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PCauseDataset(train_path, transform=transform_augmentation)\n",
    "test_dataset = PCauseDataset(test_path)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the model architecture\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.inBlock = GenBlock(in_channels, mid_channels, kernel_size=4, stride=1, padding=0)  # 4x4\n",
    "        self.net = nn.Sequential(\n",
    "            GenBlock(mid_channels + 1, mid_channels // 2, kernel_size=4, stride=2, padding=1),  # 8x8\n",
    "            GenBlock(mid_channels // 2, mid_channels // 4, kernel_size=4, stride=2, padding=1),  # 16x16\n",
    "            GenBlock(mid_channels // 4, mid_channels // 8, kernel_size=4, stride=2, padding=1),  # 32x32\n",
    "            GenBlock(mid_channels // 8, mid_channels // 16, kernel_size=4, stride=2, padding=1),  # 64x64\n",
    "            nn.ConvTranspose2d(mid_channels // 16, out_channels, kernel_size=4, stride=2, padding=1),  # 128x128\n",
    "            nn.Tanh())\n",
    "\n",
    "        self.embedding = nn.Embedding(3, 50)\n",
    "        self.linear = nn.Linear(50, 4 * 4)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        y = self.embedding(label)\n",
    "        y = self.linear(y).view(-1, 1, 4, 4)\n",
    "        x = self.inBlock(x)\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        return self.net(x)\n",
    "\n",
    "class GenBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(GenBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        return self.dropout(self.relu(x))\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            DisBlock(mid_channels, mid_channels * 2, 4, 2, 1),\n",
    "            DisBlock(mid_channels * 2, mid_channels * 4, 4, 2, 1),\n",
    "            DisBlock(mid_channels * 4, mid_channels * 8, 4, 2, 1),\n",
    "            DisBlock(mid_channels * 8, mid_channels * 16, 4, 2, 1)\n",
    "        )\n",
    "\n",
    "        self.Slinear = nn.Linear(mid_channels * 16 * 4 * 4, 1)\n",
    "        self.Clinear = nn.Linear(mid_channels * 16 * 4 * 4, 3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        y1 = self.sigmoid(self.Slinear(x)).view(-1)\n",
    "        y2 = self.softmax(self.Clinear(x))\n",
    "        return y1, y2\n",
    "\n",
    "class DisBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DisBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
